{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142829a8-2374-40bb-ae3d-836d07c7eb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612737.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612738.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612739.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612740.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612741.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612742.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612743.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612744.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612745.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612746.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612747.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612748.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612749.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612750.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612751.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612752.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612753.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612754.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612755.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612756.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612757.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612758.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612759.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612760.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612761.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612762.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612763.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612764.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612765.csv\n",
      "https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/2026/1610612766.csv\n",
      "[]\n",
      "5532\n",
      "year_files/2026_games.csv\n",
      "Year: 2026\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_ID</th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>NICKNAME</th>\n",
       "      <th>TEAM_ID</th>\n",
       "      <th>TEAM_ABBREVIATION</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W_PCT</th>\n",
       "      <th>...</th>\n",
       "      <th>AVG_SPEED</th>\n",
       "      <th>DIST_FEET</th>\n",
       "      <th>DIST_MILES_DEF</th>\n",
       "      <th>DIST_MILES_OFF</th>\n",
       "      <th>AVG_SPEED_DEF</th>\n",
       "      <th>AVG_SPEED_OFF</th>\n",
       "      <th>DIST_MILES</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>playoffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1631260</td>\n",
       "      <td>AJ Green</td>\n",
       "      <td>AJ</td>\n",
       "      <td>1610612749</td>\n",
       "      <td>MIL</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.80</td>\n",
       "      <td>10739.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.91</td>\n",
       "      <td>5.14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2026</td>\n",
       "      <td>20251022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1642358</td>\n",
       "      <td>AJ Johnson</td>\n",
       "      <td>AJ</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.45</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.44</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2026</td>\n",
       "      <td>20251022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1642846</td>\n",
       "      <td>Ace Bailey</td>\n",
       "      <td>Ace</td>\n",
       "      <td>1610612762</td>\n",
       "      <td>UTA</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.22</td>\n",
       "      <td>7303.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.32</td>\n",
       "      <td>4.13</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2026</td>\n",
       "      <td>20251022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1641737</td>\n",
       "      <td>Adem Bona</td>\n",
       "      <td>Adem</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>PHI</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.42</td>\n",
       "      <td>5097.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2026</td>\n",
       "      <td>20251022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1642259</td>\n",
       "      <td>Alex Sarr</td>\n",
       "      <td>Alex</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.64</td>\n",
       "      <td>9400.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.61</td>\n",
       "      <td>4.66</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2026</td>\n",
       "      <td>20251022</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5527</th>\n",
       "      <td>1630249</td>\n",
       "      <td>Vít Krejčí</td>\n",
       "      <td>Vít</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>ATL</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.20</td>\n",
       "      <td>11722.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.78</td>\n",
       "      <td>4.74</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2026</td>\n",
       "      <td>20251123</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5528</th>\n",
       "      <td>1642905</td>\n",
       "      <td>Yang Hansen</td>\n",
       "      <td>ang Hansen</td>\n",
       "      <td>1610612757</td>\n",
       "      <td>POR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.91</td>\n",
       "      <td>5984.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.52</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2026</td>\n",
       "      <td>20251123</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>1642949</td>\n",
       "      <td>Yanic Konan Niederhäuser</td>\n",
       "      <td>Yanic Konan</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>LAC</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1183.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.02</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2026</td>\n",
       "      <td>20251123</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5530</th>\n",
       "      <td>1642258</td>\n",
       "      <td>Zaccharie Risacher</td>\n",
       "      <td>Zaccharie</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.46</td>\n",
       "      <td>8045.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.09</td>\n",
       "      <td>4.85</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2026</td>\n",
       "      <td>20251123</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5531</th>\n",
       "      <td>1630533</td>\n",
       "      <td>Ziaire Williams</td>\n",
       "      <td>Ziaire</td>\n",
       "      <td>1610612751</td>\n",
       "      <td>BKN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.19</td>\n",
       "      <td>10213.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>4.15</td>\n",
       "      <td>4.66</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2026</td>\n",
       "      <td>20251123</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5532 rows × 432 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PLAYER_ID               PLAYER_NAME     NICKNAME     TEAM_ID  \\\n",
       "0       1631260                  AJ Green           AJ  1610612749   \n",
       "1       1642358                AJ Johnson           AJ  1610612764   \n",
       "2       1642846                Ace Bailey          Ace  1610612762   \n",
       "3       1641737                 Adem Bona         Adem  1610612755   \n",
       "4       1642259                 Alex Sarr         Alex  1610612764   \n",
       "...         ...                       ...          ...         ...   \n",
       "5527    1630249                Vít Krejčí          Vít  1610612737   \n",
       "5528    1642905               Yang Hansen   ang Hansen  1610612757   \n",
       "5529    1642949  Yanic Konan Niederhäuser  Yanic Konan  1610612746   \n",
       "5530    1642258        Zaccharie Risacher    Zaccharie  1610612737   \n",
       "5531    1630533           Ziaire Williams       Ziaire  1610612751   \n",
       "\n",
       "     TEAM_ABBREVIATION   AGE  GP  W  L  W_PCT  ...  AVG_SPEED  DIST_FEET  \\\n",
       "0                  MIL  26.0   1  1  0    1.0  ...       4.80    10739.0   \n",
       "1                  WAS  20.0   1  0  1    0.0  ...       3.45      694.0   \n",
       "2                  UTA  19.0   1  1  0    1.0  ...       4.22     7303.0   \n",
       "3                  PHI  22.0   1  1  0    1.0  ...       4.42     5097.0   \n",
       "4                  WAS  20.0   1  0  1    0.0  ...       4.64     9400.0   \n",
       "...                ...   ...  .. .. ..    ...  ...        ...        ...   \n",
       "5527               ATL  25.0   1  1  0    1.0  ...       4.20    11722.0   \n",
       "5528               POR  20.0   1  0  1    0.0  ...       3.91     5984.0   \n",
       "5529               LAC  22.0   1  0  1    0.0  ...       3.60     1183.0   \n",
       "5530               ATL  20.0   1  1  0    1.0  ...       4.46     8045.0   \n",
       "5531               BKN  24.0   1  0  1    0.0  ...       4.19    10213.0   \n",
       "\n",
       "      DIST_MILES_DEF  DIST_MILES_OFF  AVG_SPEED_DEF  AVG_SPEED_OFF  \\\n",
       "0                1.0             1.1           4.91           5.14   \n",
       "1                0.1             0.1           5.44           9.45   \n",
       "2                0.7             0.7           4.32           4.13   \n",
       "3                0.4             0.5           3.94           4.02   \n",
       "4                0.9             0.9           4.61           4.66   \n",
       "...              ...             ...            ...            ...   \n",
       "5527             1.1             1.1           3.78           4.74   \n",
       "5528             0.6             0.6           4.05           4.52   \n",
       "5529             0.1             0.1           4.02           3.26   \n",
       "5530             0.7             0.8           4.09           4.85   \n",
       "5531             0.9             1.1           4.15           4.66   \n",
       "\n",
       "      DIST_MILES  year      date  playoffs  \n",
       "0            2.0  2026  20251022     False  \n",
       "1            0.1  2026  20251022     False  \n",
       "2            1.4  2026  20251022     False  \n",
       "3            1.0  2026  20251022     False  \n",
       "4            1.8  2026  20251022     False  \n",
       "...          ...   ...       ...       ...  \n",
       "5527         2.2  2026  20251123     False  \n",
       "5528         1.1  2026  20251123     False  \n",
       "5529         0.2  2026  20251123     False  \n",
       "5530         1.5  2026  20251123     False  \n",
       "5531         1.9  2026  20251123     False  \n",
       "\n",
       "[5532 rows x 432 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nba_api.stats.static import players,teams\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from requests.exceptions import RequestException # Import for better error handling\n",
    "def format_date_to_url(date):\n",
    "    # Convert date from YYYYMMDD to datetime object\n",
    "    date_obj = datetime.strptime(str(date), '%Y%m%d')\n",
    "    \n",
    "    # Format the date as MM%2FDD%2FYYYY\n",
    "    formatted_date = date_obj.strftime('%m%%2F%d%%2F%Y')\n",
    "    \n",
    "    return formatted_date\n",
    "\n",
    "# Example usage\n",
    "\n",
    "def pull_data(url, max_retries=3, delay_seconds=5):\n",
    "    \"\"\"\n",
    "    Pulls data from a URL with retry logic for handling transient errors.\n",
    "\n",
    "    Args:\n",
    "        url (str): The API endpoint URL.\n",
    "        max_retries (int): The maximum number of times to retry the request.\n",
    "        delay_seconds (int): The time in seconds to wait between retries.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame or None: The parsed data as a DataFrame, or None if all retries fail.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Host\": \"stats.nba.com\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Referer\": \"https://stats.nba.com/\",\n",
    "        \"Origin\": \"https://stats.nba.com\",\n",
    "        \"Sec-Fetch-Dest\": \"empty\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    }\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # --- API Request Attempt ---\n",
    "            print(f\"Attempt {attempt + 1} of {max_retries} to pull data from {url}\")\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)\n",
    "            json_data = response.json()\n",
    "\n",
    "            # --- Data Parsing Logic (from your original code) ---\n",
    "            if len(json_data.get(\"resultSets\", [])) == 1:\n",
    "                data = json_data[\"resultSets\"][0][\"rowSet\"]\n",
    "                columns = json_data[\"resultSets\"][0][\"headers\"]\n",
    "                df = pd.DataFrame.from_records(data, columns=columns)\n",
    "            else:\n",
    "                # Assuming this else block is for a different structure\n",
    "                data = json_data[\"resultSets\"][\"rowSet\"]\n",
    "                # Assuming 'headers' is a list of dicts and the second element has 'columnNames'\n",
    "                columns = json_data[\"resultSets\"][\"headers\"][1]['columnNames']\n",
    "                df = pd.DataFrame.from_records(data, columns=columns)\n",
    "\n",
    "            time.sleep(1.2)\n",
    "            print('pulled successfully')\n",
    "            return df\n",
    "\n",
    "        except (RequestException, ValueError, KeyError) as e:\n",
    "            # Handle request errors (e.g., network issues, timeouts) or JSON/Key errors\n",
    "            print(f\"Error on attempt {attempt + 1}: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Waiting {delay_seconds} seconds before retrying...\")\n",
    "                time.sleep(delay_seconds)\n",
    "            else:\n",
    "                print(f\"Max retries ({max_retries}) reached. Failed to pull data.\")\n",
    "                # You can log the error or return a specific value here\n",
    "                time.sleep(1.2) # Maintain the original delay even on final failure before returning\n",
    "                return None # Return None or raise an exception if preferred\n",
    "\n",
    "    return None # Should not be reached, but good practice\n",
    "\n",
    "\n",
    "def pull_game_level(dateframe, start_year,end_year,ps=False):\n",
    "    stype = 'Regular%20Season'\n",
    "    trail=''\n",
    "    if ps == True:\n",
    "        stype='Playoffs'\n",
    "        trail='ps'\n",
    "    dframes = []\n",
    "    shotcolumns = ['FGA_FREQUENCY', 'FGM', 'FGA', 'FG_PCT', 'EFG_PCT', 'FG2A_FREQUENCY', 'FG2M', 'FG2A', 'FG2_PCT', \n",
    "                   'FG3A_FREQUENCY', 'FG3M', 'FG3A', 'FG3_PCT']\n",
    "    \n",
    "    unit='Player'\n",
    "    for year in range(start_year, end_year):\n",
    "        count=0\n",
    "        countframe=dateframe[dateframe.year==year].reset_index()\n",
    "        year_frame=[]\n",
    "        test = False\n",
    "        game_date = 20250125\n",
    "        if test != False:\n",
    "            countframe=countframe[countframe.GAME_DATE<game_date]\n",
    "\n",
    "        year_dates = countframe['GAME_DATE'].unique().tolist()\n",
    "        if os.path.exists('year_files/'+str(year)+trail+'_games.csv'):\n",
    "            df= pd.read_csv('year_files/'+str(year)+trail+'_games.csv')\n",
    "            df['date']=df['date'].astype(int)\n",
    "            df.sort_values(by='date',ascending=False)\n",
    "            df.drop_duplicates(subset=['date','PLAYER_ID','TEAM_ID'],inplace=True)\n",
    "            if test != False:\n",
    "                df=df[df.date<game_date]\n",
    "            \n",
    "            year_frame.append(df)\n",
    "\n",
    "            year_dates=[int(date) for date in year_dates if date not in df['date'].unique().tolist()]\n",
    "            year_dates=year_dates[::-1]\n",
    "            \n",
    "\n",
    "        season = str(year - 1) + '-' + str(year)[-2:]\n",
    "        print(year_dates)\n",
    "        for date in year_dates:\n",
    "            try:\n",
    "                date_num = int(date)\n",
    "                date = format_date_to_url(date)\n",
    "    \n",
    "    \n",
    "                url = f'https://stats.nba.com/stats/leaguedashplayerstats?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PORound=&PaceAdjust=N&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&Season={season}&SeasonSegment=&SeasonType={stype}&ShotClockRange=&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "            \n",
    "                df = pull_data(url)\n",
    "    \n",
    "                url2 = f'https://stats.nba.com/stats/leaguedashplayerstats?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&MeasureType=Advanced&Month=0&OpponentTeamID=0&Outcome=&PORound=&PaceAdjust=N&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&Season={season}&SeasonSegment=&SeasonType={stype}&ShotClockRange=&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                df2 = pull_data(url2)\n",
    "    \n",
    "                url3 = f'https://stats.nba.com/stats/leaguedashptstats?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=&PerMode=Totals&PlayerExperience=&PlayerOrTeam={unit}&PlayerPosition=&PtMeasureType=Passing&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                df3 = pull_data(url3)\n",
    "    \n",
    "                url4 = f'https://stats.nba.com/stats/leaguedashptstats?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=&PerMode=Totals&PlayerExperience=&PlayerOrTeam={unit}&PlayerPosition=&PtMeasureType=Drives&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                df4 = pull_data(url4)\n",
    "    \n",
    "                url5 = f'https://stats.nba.com/stats/leaguedashptstats?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=&PerMode=Totals&PlayerExperience=&PlayerOrTeam={unit}&PlayerPosition=&PtMeasureType=Possessions&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                df5 = pull_data(url5)\n",
    "    \n",
    "                url6 = f'https://stats.nba.com/stats/leaguedashptstats?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=&PerMode=Totals&PlayerExperience=&PlayerOrTeam={unit}&PlayerPosition=&PtMeasureType=Rebounding&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                df6 = pull_data(url6)\n",
    "    \n",
    "                url7 = f'https://stats.nba.com/stats/leaguedashplayerptshot?CloseDefDistRange=0-2%20Feet%20-%20Very%20Tight&College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&DribbleRange=&GameScope=&GameSegment=&GeneralRange=&Height=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&Season={season}&SeasonSegment=&SeasonType={stype}&ShotClockRange=&ShotDistRange=&StarterBench=&TeamID=0&TouchTimeRange=&VsConference=&VsDivision=&Weight='\n",
    "                df7 = pull_data(url7)\n",
    "    \n",
    "                term = 'very_tight_'\n",
    "                df7.rename(columns={col: term + col for col in shotcolumns}, inplace=True)\n",
    "                \n",
    "                url8 = 'https://stats.nba.com/stats/leaguedashplayerptshot?CloseDefDistRange=2-4%20Feet%20-%20Tight&College=&Conference=&Country=&DateFrom=' + date + '&DateTo=' + date + '&Division=&DraftPick=&DraftYear=&DribbleRange=&GameScope=&GameSegment=&GeneralRange=&Height=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&Season=' + season + '&SeasonSegment=&SeasonType='+stype+'&ShotClockRange=&ShotDistRange=&StarterBench=&TeamID=0&TouchTimeRange=&VsConference=&VsDivision=&Weight='\n",
    "                df8 = pull_data(url8)\n",
    "                term = 'tight_'\n",
    "                df8.rename(columns={col: term + col for col in shotcolumns},inplace=True)\n",
    "    \n",
    "                url9 = 'https://stats.nba.com/stats/leaguedashplayerptshot?CloseDefDistRange=4-6%20Feet%20-%20Open&College=&Conference=&Country=&DateFrom=' + date + '&DateTo=' + date + '&Division=&DraftPick=&DraftYear=&DribbleRange=&GameScope=&GameSegment=&GeneralRange=&Height=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&Season=' + season + '&SeasonSegment=&SeasonType='+stype+'&ShotClockRange=&ShotDistRange=&StarterBench=&TeamID=0&TouchTimeRange=&VsConference=&VsDivision=&Weight='\n",
    "                df9 = pull_data(url9)\n",
    "                term = 'open_'\n",
    "                df9.rename(columns={col: term + col for col in shotcolumns},inplace=True)\n",
    "    \n",
    "                url10 = 'https://stats.nba.com/stats/leaguedashplayerptshot?CloseDefDistRange=6%2B%20Feet%20-%20Wide%20Open&College=&Conference=&Country=&DateFrom=' + date + '&DateTo=' + date + '&Division=&DraftPick=&DraftYear=&DribbleRange=&GameScope=&GameSegment=&GeneralRange=&Height=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&Season=' + season + '&SeasonSegment=&SeasonType='+stype+'&ShotClockRange=&ShotDistRange=&StarterBench=&TeamID=0&TouchTimeRange=&VsConference=&VsDivision=&Weight='\n",
    "                df10 = pull_data(url10)\n",
    "                term = 'wide_open_'\n",
    "                df10.rename(columns={col: term + col for col in shotcolumns},inplace=True)\n",
    "                url11 = 'https://stats.nba.com/stats/leaguedashptstats?College=&Conference=&Country=&DateFrom=' + date + '&DateTo=' + date + '&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=&PerMode=Totals&PlayerExperience=&PlayerOrTeam=Player&PlayerPosition=&PtMeasureType=PullUpShot&Season=' + season + '&SeasonSegment=&SeasonType='+stype+'&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                df11 = pull_data(url11) \n",
    "                shotcolumns2=shotcolumns+['EFG%']\n",
    "                term='pullup_'\n",
    "                df11.rename(columns={col: term + col for col in shotcolumns2},inplace=True)\n",
    "    \n",
    "                url12 = 'https://stats.nba.com/stats/leaguedashptstats?College=&Conference=&Country=&DateFrom=' + date + '&DateTo=' + date + '&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=&PerMode=Totals&PlayerExperience=&PlayerOrTeam=Player&PlayerPosition=&PtMeasureType=Efficiency&Season=' + season + '&SeasonSegment=&SeasonType='+stype+'&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "\n",
    "\n",
    "                df12 = pull_data(url12) \n",
    "                url13=f\"https://stats.nba.com/stats/leaguedashplayershotlocations?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&DistanceRange=By%20Zone&Division=&DraftPick=&DraftYear=&GameScope=&GameSegment=&Height=&ISTRound=&LastNGames=0&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PaceAdjust=N&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&Season={season}&SeasonSegment=&SeasonType={stype}&ShotClockRange=&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight=\"\n",
    "                \n",
    "                df13=pull_data(url13)\n",
    "    \n",
    "                zone_columns=['PLAYER_ID', 'PLAYER_NAME', 'TEAM_ID', 'TEAM_ABBREVIATION', 'AGE', 'NICKNAME',\n",
    "                 'RA_FGM', 'RA_FGA', 'RA_FG_PCT',               # Restricted Area\n",
    "                 'ITP_FGM', 'ITP_FGA', 'ITP_FG_PCT',             # In The Paint (Non-RA)\n",
    "                 'MID_FGM', 'MID_FGA', 'MID_FG_PCT',             # Mid Range\n",
    "                 'LEFT_CORNER_3_FGM', 'LEFT_CORNER_3_FGA', 'LEFT_CORNER_3_FG_PCT',  # Left Corner 3\n",
    "                 'RIGHT_CORNER_3_FGM', 'RIGHT_CORNER_3_FGA', 'RIGHT_CORNER_3_FG_PCT', # Right Corner 3\n",
    "          \n",
    "    \n",
    "                               # All Corner 3s\n",
    "                 'ABOVE_BREAK_3_FGM', 'ABOVE_BREAK_3_FGA', 'ABOVE_BREAK_3_FG_PCT', \n",
    "                       'BACKCOURT_FGM', 'BACKCOURT_FGA', 'BACKCOURT_FG_PCT', # Right Corner 3\n",
    "                              \n",
    "                              'CORNER_3_FGM', 'CORNER_3_FGA', 'CORNER_3_FG_PCT'  ]  # Above the Break 3\n",
    "    \n",
    "                df13.columns=zone_columns\n",
    "                url14=f\"https://stats.nba.com/stats/leaguedashptdefend?College=&Conference=&Country=&DateFrom{date}=&DateTo={date}&DefenseCategory=Less%20Than%206Ft&Division=&DraftPick=&DraftYear=&GameSegment=&Height=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight=\"\n",
    "                df14=pull_data(url14)\n",
    "                df14.rename(columns={'CLOSE_DEF_PERSON_ID':'PLAYER_ID'},inplace=True)\n",
    "    \n",
    "                url15=f\"https://stats.nba.com/stats/leaguedashplayershotlocations?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&DistanceRange=5ft%20Range&Division=&DraftPick=&DraftYear=&GameScope=&GameSegment=&Height=&ISTRound=&LastNGames=0&Location=&MeasureType=Base&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PaceAdjust=N&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&Season={season}&SeasonSegment=&SeasonType={stype}&ShotClockRange=&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight=\"\n",
    "                df15=pull_data(url15)\n",
    "                df15.columns=['PLAYER_ID', 'PLAYER_NAME', 'TEAM_ID', 'TEAM_ABBR', 'AGE', 'NICKNAME',\n",
    "                 'FGM_LT_5', 'FGA_LT_5', 'FGP_LT_5',      # Less than 5 feet\n",
    "                 'FGM_5_9', 'FGA_5_9', 'FGP_5_9',         # 5-9 feet\n",
    "                 'FGM_10_14', 'FGA_10_14', 'FGP_10_14',   # 10-14 feet\n",
    "                 'FGM_15_19', 'FGA_15_19', 'FGP_15_19',   # 15-19 feet\n",
    "                 'FGM_20_24', 'FGA_20_24', 'FGP_20_24',   # 20-24 feet\n",
    "                 'FGM_25_29', 'FGA_25_29', 'FGP_25_29',   # 25-29 feet\n",
    "                 'FGM_30_34', 'FGA_30_34', 'FGP_30_34',   # 30-34 feet\n",
    "                 'FGM_35_39', 'FGA_35_39', 'FGP_35_39',   # 35-39 feet\n",
    "                 'FGM_40_PLUS', 'FGA_40_PLUS', 'FGP_40_PLUS'  # 40+ feet\n",
    "                ]\n",
    "                url16 = f'https://stats.nba.com/stats/leaguedashptstats?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=&PerMode=Totals&PlayerExperience=&PlayerOrTeam={unit}&PlayerPosition=&PtMeasureType=CatchShoot&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                df16=pull_data(url16)\n",
    "    \n",
    "                \n",
    "                url17 = f'https://stats.nba.com/stats/leaguedashteamstats?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&MeasureType=Advanced&Month=0&OpponentTeamID=0&Outcome=&PORound=&PaceAdjust=N&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&Season={season}&SeasonSegment=&SeasonType=Playoffs&ShotClockRange=&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                df17 = pull_data(url17)\n",
    "                df17=df17[['TEAM_ID','POSS']]\n",
    "                df17.columns=['TEAM_ID','team_poss']\n",
    "    \n",
    "                poss_map=dict(zip(df17['TEAM_ID'],df17['team_poss']  ))\n",
    "    \n",
    "                df['team_poss']=df['TEAM_ID'].map(poss_map)\n",
    "\n",
    "                url18 = f'https://stats.nba.com/stats/leaguedashptdefend?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&DefenseCategory=Overall&Division=&DraftPick=&DraftYear=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "            \n",
    "                df18 = pull_data(url18)\n",
    "                df18.rename(columns={'CLOSE_DEF_PERSON_ID': 'PLAYER_ID'}, inplace=True)\n",
    "                df18.rename(columns={col: f'overall_def_{col}' for col in df8.columns if col != 'PLAYER_ID'}, inplace=True)\n",
    "\n",
    "                # Link 2: 3-pointers defense stats\n",
    "                url19 = f'https://stats.nba.com/stats/leaguedashptdefend?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&DefenseCategory=3%20Pointers&Division=&DraftPick=&DraftYear=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                \n",
    "                df19 = pull_data(url19)\n",
    "\n",
    "                df19.rename(columns={'CLOSE_DEF_PERSON_ID': 'PLAYER_ID'}, inplace=True)\n",
    "                df19.rename(columns={col: f'three_pt_def_{col}' for col in df19.columns if col != 'PLAYER_ID'}, inplace=True)\n",
    "  \n",
    "                \n",
    "                # Link 3: 2-pointers defense stats\n",
    "                url20 = f'https://stats.nba.com/stats/leaguedashptdefend?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&DefenseCategory=2%20Pointers&Division=&DraftPick=&DraftYear=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "     \n",
    "                df20 = pull_data(url20)\n",
    "\n",
    "                df20.rename(columns={'CLOSE_DEF_PERSON_ID': 'PLAYER_ID'}, inplace=True)\n",
    "                df20.rename(columns={col: f'two_pt_def_{col}' for col in df20.columns if col != 'PLAYER_ID'}, inplace=True)\n",
    "\n",
    "                \n",
    "                # Link 4: Less than 6ft defense stats\n",
    "                url21 = f'https://stats.nba.com/stats/leaguedashptdefend?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&DefenseCategory=Less%20Than%206Ft&Division=&DraftPick=&DraftYear=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "               \n",
    "                df21 = pull_data(url21)\n",
    "                df21.rename(columns={'CLOSE_DEF_PERSON_ID': 'PLAYER_ID'}, inplace=True)\n",
    "                df21.rename(columns={col: f'less_6ft_def_{col}' for col in df21.columns if col != 'PLAYER_ID'}, inplace=True)\n",
    "    \n",
    "                # Link 5: Less than 10ft defense stats\n",
    "                url22 = f'https://stats.nba.com/stats/leaguedashptdefend?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&DefenseCategory=Less%20Than%2010Ft&Division=&DraftPick=&DraftYear=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                \n",
    "                df22 = pull_data(url22)\n",
    "                df22.rename(columns={'CLOSE_DEF_PERSON_ID': 'PLAYER_ID'}, inplace=True)\n",
    "                df22.rename(columns={col: f'less_10ft_def_{col}' for col in df22.columns if col != 'PLAYER_ID'}, inplace=True)\n",
    "                \n",
    "                \n",
    "                # Link 6: Less than 15ft defense stats\n",
    "                url23 = f'https://stats.nba.com/stats/leaguedashptdefend?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&DefenseCategory=Greater%20Than%2015Ft&Division=&DraftPick=&DraftYear=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=PerGame&Period=0&PlayerExperience=&PlayerPosition=&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "            \n",
    "                df23 = pull_data(url6)\n",
    "                df23.rename(columns={'CLOSE_DEF_PERSON_ID': 'PLAYER_ID'}, inplace=True)\n",
    "                df23.rename(columns={col: f'more_15ft_def_{col}' for col in df23.columns if col != 'PLAYER_ID'}, inplace=True)\n",
    "        \n",
    "                \n",
    "\n",
    "                url24 = f'https://stats.nba.com/stats/leaguehustlestatsplayer?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PaceAdjust=N&PerMode=PerGame&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&Season={season}&SeasonSegment=&SeasonType={stype}&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "            \n",
    "                df24 = pull_data(url24)\n",
    "                df24.rename(columns={col: f'hustle_{col}' for col in df24.columns if col != 'PLAYER_ID'}, inplace=True)\n",
    "       \n",
    "                # Link 8: Post touch stats\n",
    "                url25 = f'https://stats.nba.com/stats/leaguedashptstats?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=PerGame&PlayerExperience=&PlayerOrTeam=Player&PlayerPosition=&PtMeasureType=PostTouch&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                \n",
    "                df25 = pull_data(url25)\n",
    "                df25.rename(columns={col: f'post_touch_{col}' for col in df25.columns if col != 'PLAYER_ID'}, inplace=True)\n",
    "      \n",
    "                \n",
    "                # Link 9: Speed distance stats\n",
    "                url26 = f'https://stats.nba.com/stats/leaguedashptstats?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&Month=0&OpponentTeamID=0&Outcome=&PORound=0&PerMode=PerGame&PlayerExperience=&PlayerOrTeam=Player&PlayerPosition=&PtMeasureType=SpeedDistance&Season={season}&SeasonSegment=&SeasonType={stype}&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                \n",
    "                df26 = pull_data(url26)\n",
    "                df26 = pull_data(url26)\n",
    "                frames = [df2, df3, df4, df5, df6, df7, df8, df9, df10,df11,df12,df13,df14,df15,df16,df18,df19,df20,df21,df22,df23,df24,df25,df26]\n",
    "                for frame in frames:\n",
    "                    \n",
    "                    joined_columns = set(frame.columns) - set(df.columns)\n",
    "                    joined_columns = list(joined_columns)\n",
    "                    joined_columns.append('PLAYER_ID')\n",
    "                    frame = frame[joined_columns]\n",
    "    \n",
    "                    df = df.merge(frame, on='PLAYER_ID',how='left').reset_index(drop=True)\n",
    "    \n",
    "                df['year'] = year\n",
    "                df['date']=date_num\n",
    "                extra_columns = [\n",
    "                '_PLAYER_NAME', \n",
    "                '_PLAYER_LAST_TEAM_ID', \n",
    "                '_GP', \n",
    "                '_PLAYER_POSITION', \n",
    "                '_PLAYER_LAST_TEAM_ABBREVIATION', \n",
    "                '_PLAYER_ID',\n",
    "                '_MIN',\n",
    "                '_TEAM_ABBREVIATUON',\n",
    "                '_G',\n",
    "                '_W',\n",
    "                '_L',\n",
    "                '_MIN',\n",
    "                '_AGE',\n",
    "                '_TEAM_ID'\n",
    "            ]\n",
    "\n",
    "    \n",
    "                cols_to_drop = [col for col in df.columns if any(col.endswith(ex_col) for ex_col in extra_columns)]\n",
    "                df = df.drop(columns=cols_to_drop)\n",
    "      \n",
    "                year_frame.append(df)\n",
    "                count+=1\n",
    "                print(date_num)\n",
    "                if count %10==0:\n",
    "            \n",
    "                    yeardata=pd.concat(year_frame)\n",
    "                    print(len(yeardata))\n",
    "                    yeardata['playoffs']=ps\n",
    "                    yeardata.to_csv(str(year)+trail+'_games.csv',index=False)\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                print(str(date_num))\n",
    "                time.sleep(1)\n",
    "    \n",
    "\n",
    "        yeardata=pd.concat(year_frame)\n",
    "        print(len(yeardata))\n",
    "        yeardata['playoffs']=ps\n",
    "        print('year_files/'+str(year)+trail+'_games.csv')\n",
    "        yeardata.to_csv('year_files/'+str(year)+trail+'_games.csv',index=False)\n",
    "        dframes.append(yeardata)\n",
    "        print(f\"Year: {year}\")\n",
    "\n",
    "    total = pd.concat(dframes)\n",
    "    return total\n",
    "\n",
    "start_year=2026\n",
    "end_year=2027\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_dates(start_year, end_year, ps=False):\n",
    "    trail = 'ps' if ps else ''\n",
    "    dates = []\n",
    "\n",
    "    for year in range(start_year, end_year):\n",
    "        for team in teams.get_teams():\n",
    "            team_id = team['id']\n",
    "            base = 'https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/team/'\n",
    "            path = f\"{base}{year}{trail}/{team_id}.csv\"\n",
    "            print(path)\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(path)\n",
    "                df = df[['PLAYER_ID', 'TEAM_ID', 'HTM', 'VTM', 'GAME_DATE', 'GAME_ID']]\n",
    "                df.sort_values(by='GAME_DATE', inplace=True)\n",
    "                df.drop_duplicates(inplace=True)\n",
    "                df['year'] = year\n",
    "                dates.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {path}: {e}\")\n",
    "    \n",
    "    return pd.concat(dates, ignore_index=True) if dates else pd.DataFrame()\n",
    "ps=False\n",
    "dateframe=get_dates(start_year,end_year,ps=ps)\n",
    "\n",
    "dates=dateframe['GAME_DATE'].unique().tolist()\n",
    "dates.sort()\n",
    "\n",
    "df= pull_game_level(dateframe,start_year,end_year,ps=ps)\n",
    "#data=pull_game_level(dates)\n",
    "df\n",
    "df.drop_duplicates(subset=['PLAYER_ID','TEAM_ID','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a58119-d533-4085-8e09-d4ac71447d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20251021,\n",
       " 20251022,\n",
       " 20251023,\n",
       " 20251024,\n",
       " 20251025,\n",
       " 20251026,\n",
       " 20251027,\n",
       " 20251028,\n",
       " 20251029,\n",
       " 20251030,\n",
       " 20251031,\n",
       " 20251101,\n",
       " 20251102,\n",
       " 20251103,\n",
       " 20251104,\n",
       " 20251105,\n",
       " 20251106,\n",
       " 20251107,\n",
       " 20251108,\n",
       " 20251109,\n",
       " 20251110,\n",
       " 20251111,\n",
       " 20251112,\n",
       " 20251113,\n",
       " 20251114,\n",
       " 20251115,\n",
       " 20251116,\n",
       " 20251117,\n",
       " 20251118,\n",
       " 20251119,\n",
       " 20251120,\n",
       " 20251121,\n",
       " 20251122,\n",
       " 20251123]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates.sort()\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a0ebe6c-30db-4aa8-bc66-7f409a2e9a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndateframe = pd.read_csv('../../shot_data/game_dates.csv')\\ndateframe=dateframe[dateframe.season=='2024-25']\\ndateframe.sort_values(by='date',inplace=True,ascending=False)\\n\\nprint(dateframe.head(30))\\nprint(dateframe.columns)\\ndateframe=dateframe[['date','GAME_ID','TEAM_ID']]\\ndateframe.date.max()\\n\\nprint(len(test))\\nmerge=test.merge(dateframe,how='left')\\nprint(len(merge))\\nmerge\\n\\n\\nmerge[merge.GAME_ID.isna()]\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dateframe = pd.read_csv('../../shot_data/game_dates.csv')\n",
    "dateframe=dateframe[dateframe.season=='2024-25']\n",
    "dateframe.sort_values(by='date',inplace=True,ascending=False)\n",
    "\n",
    "print(dateframe.head(30))\n",
    "print(dateframe.columns)\n",
    "dateframe=dateframe[['date','GAME_ID','TEAM_ID']]\n",
    "dateframe.date.max()\n",
    "\n",
    "print(len(test))\n",
    "merge=test.merge(dateframe,how='left')\n",
    "print(len(merge))\n",
    "merge\n",
    "\n",
    "\n",
    "merge[merge.GAME_ID.isna()]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134c81d-b647-442a-a4be-c34775e5212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if ps==False:\n",
    "    trail=''\n",
    "else:\n",
    "    trail='ps'\n",
    "print(trail)\n",
    "frames= []\n",
    "count=0\n",
    "index_master=pd.read_csv('https://raw.githubusercontent.com/gabriel1200/site_Data/refs/heads/master/index_master.csv')\n",
    "index_master=index_master[index_master.team!='TOT']\n",
    "index_master['team_id']=index_master['team_id'].astype(int)\n",
    "index_master['nba_id']=index_master['nba_id'].astype(int)\n",
    "\n",
    "\n",
    "game_dates= pd.read_csv('https://raw.githubusercontent.com/gabriel1200/shot_data/refs/heads/master/game_dates.csv')\n",
    "team_id_map = game_dates[['team', 'TEAM_ID']].drop_duplicates().set_index('team')['TEAM_ID'].to_dict()\n",
    "game_dates['year'] = game_dates['season'].apply(lambda x: int(x.split('-')[0]) + 1)\n",
    "# 2. Map the 'opp_team' column using this dictionary to create the new column\n",
    "game_dates['OPP_TEAM_ID'] = game_dates['opp_team'].map(team_id_map)\n",
    "for year in range(start_year,end_year):\n",
    "    # Load the game data for the specific year.\n",
    "    games_collected=[]\n",
    "    df = pd.read_csv(f'year_files/{year}{trail}_games.csv')\n",
    "\n",
    "    team_map=dict(zip(df['TEAM_ID'],df['TEAM_ABBREVIATION']))\n",
    "    \n",
    "    # Filter index_master for the current year.\n",
    "    year_index = index_master[index_master['year'] == year].reset_index()\n",
    "\n",
    "    # Process each unique date in the dataset.\n",
    "    for date in df['date'].unique().tolist():\n",
    "        datedf=df[df.date==date].reset_index(drop=True)\n",
    "        datedf=datedf.drop_duplicates(subset=['PLAYER_ID','date'])\n",
    "        # Filter game data by date.\n",
    "        \n",
    "        gameframe = dateframe[dateframe['GAME_DATE'] == date].reset_index()\n",
    "        gameframe.rename(columns={'GAME_DATE':'date'},inplace=True)\n",
    "        # Get the unique team and game data for the specific date from gameframe.\n",
    "        \n",
    "        to_merge = gameframe[['TEAM_ID', 'GAME_ID', 'date', 'year']].drop_duplicates().reset_index(drop=True)\n",
    "        \n",
    "\n",
    "        save_frame=datedf.merge(to_merge,on=['TEAM_ID','date','year'],how='left')\n",
    "\n",
    "      \n",
    "        save_frame.drop_duplicates(inplace=True)\n",
    "\n",
    "        \n",
    "        # Merge game data with index_master to ensure correct team alignment.\n",
    "        # Match on 'player' and 'team' columns from index_master and 'TEAM_ID' from the game data.\n",
    "\n",
    "        # Identify rows where the merge may have issues.\n",
    "        if save_frame['GAME_ID'].isna().any():\n",
    "        \n",
    "            missing=save_frame[save_frame['GAME_ID'].isna()].reset_index(drop=True)\n",
    "            print(gameframe)\n",
    "            print(missing)\n",
    "            save_frame.dropna(subset='GAME_ID',inplace=True)\n",
    "            missing.drop(columns=['GAME_ID','TEAM_ID','TEAM_ABBREVIATION'],inplace=True)\n",
    "\n",
    "            missing=missing.merge(gameframe,on=['PLAYER_ID','year','date'],how='left')\n",
    "            missing['TEAM_ABBREVIATION']=missing['TEAM_ID'].map(team_map)\n",
    "    \n",
    "            save_frame=pd.concat([save_frame,missing])\n",
    "\n",
    "        if save_frame['GAME_ID'].isna().any():\n",
    "        \n",
    "            missing=save_frame[save_frame['GAME_ID'].isna()].reset_index(drop=True)\n",
    "            missing.drop(columns='GAME_ID',inplace=True)\n",
    "            save_frame.dropna(subset='GAME_ID',inplace=True)\n",
    "            missed=[]\n",
    "            print(missing['PLAYER_ID'])\n",
    "            \n",
    "            for missed_player in missing['PLAYER_ID'].unique().tolist():\n",
    "                missing_frame=missing[missing.PLAYER_ID==missed_player].reset_index(drop=True)\n",
    "                print(missing_frame)\n",
    "                temp_index=year_index[year_index.nba_id==missed_player].reset_index(drop=True)\n",
    "                team_id=temp_index.iloc[0]['team_id']\n",
    "                team=temp_index.iloc[0]['team']\n",
    "                missing_frame['TEAM_ID']=int(team_id)\n",
    "                missing_frame['TEAM_ABBREVIATION']=team\n",
    "                missing_frame= missing_frame.merge(to_merge,on=['TEAM_ID','date','year'],how='left')\n",
    "                missed.append(missing_frame)\n",
    "\n",
    "            missing=pd.concat(missed)\n",
    "            save_frame=pd.concat([save_frame,missing])\n",
    "        if save_frame['GAME_ID'].isna().any():\n",
    "        \n",
    "            missing=save_frame[save_frame['GAME_ID'].isna()].reset_index(drop=True)\n",
    "            missing.drop(columns='GAME_ID',inplace=True)\n",
    "            save_frame.dropna(subset='GAME_ID',inplace=True)\n",
    "            missed=[]\n",
    "            print(missed_player)\n",
    "            \n",
    "            for missed_player in missing['PLAYER_ID'].unique().tolist():\n",
    "                missing_frame=missing[missing.PLAYER_ID==missed_player].reset_index(drop=True)\n",
    "                temp_index=year_index[year_index.nba_id==missed_player].reset_index(drop=True)\n",
    "                team_id=temp_index.iloc[1]['team_id']\n",
    "                team=temp_index.iloc[1]['team']\n",
    "                missing_frame['TEAM_ID']=int(team_id)\n",
    "                missing_frame['TEAM_ABBREVIATION']=team\n",
    "                missing_frame= missing_frame.merge(to_merge,on=['TEAM_ID','date','year'],how='left')\n",
    "                missed.append(missing_frame)\n",
    "\n",
    "            missing=pd.concat(missed)\n",
    "            save_frame=pd.concat([save_frame,missing])\n",
    "\n",
    "        if save_frame['GAME_ID'].isna().any():\n",
    "        \n",
    "            missing=save_frame[save_frame['GAME_ID'].isna()].reset_index(drop=True)\n",
    "            missing.drop(columns='GAME_ID',inplace=True)\n",
    "            save_frame.dropna(subset='GAME_ID',inplace=True)\n",
    "            missed=[]\n",
    "            \n",
    "            for missed_player in missing['PLAYER_ID'].unique().tolist():\n",
    "                missing_frame=missing[missing.PLAYER_ID==missed_player].reset_index(drop=True)\n",
    "                temp_index=year_index[year_index.nba_id==missed_player].reset_index(drop=True)\n",
    "                team_id=temp_index.iloc[2]['team_id']\n",
    "                team=temp_index.iloc[2]['team']\n",
    "                missing_frame['TEAM_ID']=int(team_id)\n",
    "                missing_frame['TEAM_ABBREVIATION']=team\n",
    "                missing_frame= missing_frame.merge(to_merge,on=['TEAM_ID','date','year'],how='left')\n",
    "                missed.append(missing_frame)\n",
    "\n",
    "            missing=pd.concat(missed)\n",
    "            save_frame=pd.concat([save_frame,missing])\n",
    "            \n",
    "        if save_frame['GAME_ID'].isna().any():\n",
    "            missing=save_frame[save_frame['GAME_ID'].isna()]\n",
    "            print('test point')\n",
    "            print(missing)\n",
    "        \n",
    "        # Remove any duplicate entries after the merge.\n",
    "        save_frame.drop_duplicates(inplace=True)\n",
    "        save_frame['GAME_ID']=save_frame['GAME_ID'].astype(int)\n",
    "        # Save each game by unique GAME_ID.\n",
    "        for game_id in save_frame['GAME_ID'].unique():\n",
    "            gameid_frame = save_frame[save_frame['GAME_ID'] == game_id].reset_index(drop=True)\n",
    "            gameid_frame.to_csv(f'{year}/{game_id}.csv', index=False)\n",
    "            games_collected.append(gameid_frame)\n",
    "            count += 1\n",
    "    all_games=pd.concat(games_collected)\n",
    "\n",
    "    year_dates= game_dates[game_dates.year==year]\n",
    "\n",
    "    year_dates=year_dates[['GAME_ID','TEAM_ID','opp_team','OPP_TEAM_ID']]\n",
    "    \n",
    "    year_dates.rename(columns={'opp_team':'opp_team_abbr','OPP_TEAM_ID':'opp_team_id '},inplace=True)\n",
    "    \n",
    "    all_games=all_games.merge(year_dates,how='left',on=['GAME_ID','TEAM_ID'])\n",
    "    print(all_games.tail())\n",
    "\n",
    "    all_games.to_csv('all_games/all_'+str(year)+trail+'.csv',index=False)\n",
    "    all_games.to_parquet('all_games/all_'+str(year)+trail+'.parquet', index=False)\n",
    "    #all_games.head(1).to_csv('all_games/sample.csv')\n",
    "\n",
    "        \n",
    "            \n",
    "            # Exit early for testing if more than 8 files are saved.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a89170d-a896-4374-8451-d62f50b35886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4daef91-5f3c-46a0-bbb2-e35310dff441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
