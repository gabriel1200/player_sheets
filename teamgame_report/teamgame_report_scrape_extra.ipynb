{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file for year 2014: 178 records\n",
      "Processed date: 20140419\n",
      "Processed date: 20140420\n",
      "Processed date: 20140421\n",
      "Processed date: 20140422\n",
      "Processed date: 20140423\n",
      "Processed date: 20140424\n",
      "Processed date: 20140425\n",
      "Processed date: 20140426\n",
      "Processed date: 20140427\n",
      "Processed date: 20140428\n",
      "Processed date: 20140429\n",
      "Processed date: 20140430\n",
      "Processed date: 20140501\n",
      "Processed date: 20140502\n",
      "Processed date: 20140503\n",
      "Processed date: 20140504\n",
      "Processed date: 20140505\n",
      "Processed date: 20140506\n",
      "Processed date: 20140507\n",
      "Processed date: 20140508\n",
      "Processed date: 20140509\n",
      "Processed date: 20140510\n",
      "Processed date: 20140511\n",
      "Processed date: 20140512\n",
      "Processed date: 20140513\n",
      "Processed date: 20140514\n",
      "Processed date: 20140515\n",
      "Processed date: 20140518\n",
      "Processed date: 20140519\n",
      "Processed date: 20140520\n",
      "Processed date: 20140521\n",
      "Processed date: 20140524\n",
      "Processed date: 20140525\n",
      "Processed date: 20140526\n",
      "Processed date: 20140527\n",
      "Processed date: 20140528\n",
      "Processed date: 20140529\n",
      "Processed date: 20140530\n",
      "Processed date: 20140531\n",
      "Processed date: 20140605\n",
      "Processed date: 20140608\n",
      "Processed date: 20140610\n",
      "Processed date: 20140612\n",
      "Processed date: 20140615\n",
      "Saved updated data to year_files/2014ps_teamgames_updated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def format_date_to_url(date):\n",
    "    # Convert date from YYYYMMDD to datetime object\n",
    "    date_obj = datetime.strptime(str(date), '%Y%m%d')\n",
    "    \n",
    "    # Format the date as MM%2FDD%2FYYYY\n",
    "    formatted_date = date_obj.strftime('%m%%2F%d%%2F%Y')\n",
    "    \n",
    "    return formatted_date\n",
    "\n",
    "def pull_data(url):\n",
    "    headers = {\n",
    "        \"Host\": \"stats.nba.com\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36\",\n",
    "        \"Accept\": \"application/json, text/plain, */*\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Referer\": \"https://stats.nba.com/\",\n",
    "        \"Origin\": \"https://stats.nba.com\",\n",
    "        \"Sec-Fetch-Dest\": \"empty\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "    }\n",
    "\n",
    "    json = requests.get(url, headers=headers).json()\n",
    "\n",
    "    if len(json[\"resultSets\"]) == 1:\n",
    "        data = json[\"resultSets\"][0][\"rowSet\"]\n",
    "        columns = json[\"resultSets\"][0][\"headers\"]\n",
    "        df = pd.DataFrame.from_records(data, columns=columns)\n",
    "    else:\n",
    "        data = json[\"resultSets\"][\"rowSet\"]\n",
    "        columns = json[\"resultSets\"][\"headers\"][1]['columnNames']\n",
    "        df = pd.DataFrame.from_records(data, columns=columns)\n",
    "\n",
    "    time.sleep(0.1)\n",
    "    return df\n",
    "\n",
    "def update_team_stats(start_year, end_year, ps=False):\n",
    "    \"\"\"\n",
    "    Updates existing team stats files with additional metrics\n",
    "    \"\"\"\n",
    "    trail = 'ps' if ps else ''\n",
    "    stype = 'Playoffs' if ps else 'Regular%20Season'\n",
    "    \n",
    "    for year in range(start_year, end_year):\n",
    "        # Check if the file exists\n",
    "        file_path = f'year_files/{year}{trail}_teamgames.csv'\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"File {file_path} does not exist. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Load existing data\n",
    "        existing_df = pd.read_csv(file_path)\n",
    "        print(f\"Loaded file for year {year}: {len(existing_df)} records\")\n",
    "        \n",
    "        # Get unique dates from the existing data\n",
    "        unique_dates = existing_df['date'].unique().tolist()\n",
    "        unique_dates.sort()\n",
    "        \n",
    "        # Create a dictionary to store dataframes for each date\n",
    "        date_dfs = {}\n",
    "        \n",
    "        season = str(year - 1) + '-' + str(year)[-2:]\n",
    "        \n",
    "        # Process each date\n",
    "        for date_num in unique_dates:\n",
    "            try:\n",
    "                date = format_date_to_url(date_num)\n",
    "                \n",
    "                # Misc stats URL\n",
    "                url_misc = f'https://stats.nba.com/stats/leaguedashteamstats?College=&Conference=&Country=&DateFrom={date}&DateTo={date}&Division=&DraftPick=&DraftYear=&GameScope=&GameSegment=&Height=&ISTRound=&LastNGames=0&LeagueID=00&Location=&MeasureType=Misc&Month=0&OpponentTeamID=0&Outcome=&PORound=&PaceAdjust=N&PerMode=Totals&Period=0&PlayerExperience=&PlayerPosition=&PlusMinus=N&Rank=N&Season={season}&SeasonSegment=&SeasonType={stype}&ShotClockRange=&StarterBench=&TeamID=0&VsConference=&VsDivision=&Weight='\n",
    "                \n",
    "                misc_df = pull_data(url_misc)\n",
    "                \n",
    "                # Keep only the TEAM_ID and new columns to be added\n",
    "                existing_columns = existing_df.columns.tolist()\n",
    "                misc_columns = [col for col in misc_df.columns if col not in existing_columns or col == 'TEAM_ID']\n",
    "                misc_df = misc_df[misc_columns]\n",
    "                \n",
    "                # Store in our dictionary\n",
    "                date_dfs[date_num] = misc_df\n",
    "                print(f\"Processed date: {date_num}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing date {date_num}: {str(e)}\")\n",
    "                time.sleep(1)\n",
    "        \n",
    "        # Now update the existing dataframe with the new data\n",
    "        updated_rows = []\n",
    "        \n",
    "        for i, row in existing_df.iterrows():\n",
    "            date_num = row['date']\n",
    "            team_id = row['TEAM_ID']\n",
    "            \n",
    "            if date_num in date_dfs:\n",
    "                # Find the matching row in the new data\n",
    "                match = date_dfs[date_num][date_dfs[date_num]['TEAM_ID'] == team_id]\n",
    "                \n",
    "                if not match.empty:\n",
    "                    # Update row with new columns\n",
    "                    for col in match.columns:\n",
    "                        if col != 'TEAM_ID':\n",
    "                            row[col] = match.iloc[0][col]\n",
    "            \n",
    "            updated_rows.append(row)\n",
    "        \n",
    "        # Convert back to dataframe\n",
    "        updated_df = pd.DataFrame(updated_rows)\n",
    "        \n",
    "        # Save to a new file to be safe\n",
    "        updated_file = f'year_files/{year}{trail}_teamgames_updated.csv'\n",
    "        updated_df.to_csv(updated_file, index=False)\n",
    "        print(f\"Saved updated data to {updated_file}\")\n",
    "        \n",
    "        # Optional: replace original file after verification\n",
    "        # import shutil\n",
    "        # shutil.move(updated_file, file_path)\n",
    "        # print(f\"Replaced original file with updated data\")\n",
    "\n",
    "def main():\n",
    "    start_year = 2014\n",
    "    end_year = 2015\n",
    "    \n",
    "    # Update regular season data\n",
    "    #update_team_stats(start_year, end_year, ps=False)\n",
    "   \n",
    "    update_team_stats(start_year, end_year, ps=True)\n",
    "    \n",
    "    # Uncomment to update playoff data as well\n",
    "    # update_team_stats(start_year, end_year, ps=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305\n",
      "305\n",
      "[]\n",
      "Original df columns: 305\n",
      "Updated df2 columns: 305\n",
      "Non-shared columns dropped: []\n",
      "Number of rows in df: 178\n",
      "Number of rows in newdf: 178\n",
      "305\n",
      "The DataFrames are equal.\n",
      "305\n",
      "305\n",
      "[]\n",
      "Original df columns: 305\n",
      "Updated df2 columns: 305\n",
      "Non-shared columns dropped: []\n",
      "Number of rows in df: 162\n",
      "Number of rows in newdf: 162\n",
      "305\n",
      "The DataFrames are equal.\n",
      "305\n",
      "305\n",
      "[]\n",
      "Original df columns: 305\n",
      "Updated df2 columns: 305\n",
      "Non-shared columns dropped: []\n",
      "Number of rows in df: 172\n",
      "Number of rows in newdf: 172\n",
      "305\n",
      "The DataFrames are equal.\n",
      "305\n",
      "305\n",
      "[]\n",
      "Original df columns: 305\n",
      "Updated df2 columns: 305\n",
      "Non-shared columns dropped: []\n",
      "Number of rows in df: 158\n",
      "Number of rows in newdf: 158\n",
      "305\n",
      "The DataFrames are equal.\n",
      "305\n",
      "305\n",
      "[]\n",
      "Original df columns: 305\n",
      "Updated df2 columns: 305\n",
      "Non-shared columns dropped: []\n",
      "Number of rows in df: 164\n",
      "Number of rows in newdf: 164\n",
      "305\n",
      "The DataFrames are equal.\n",
      "305\n",
      "305\n",
      "[]\n",
      "Original df columns: 305\n",
      "Updated df2 columns: 305\n",
      "Non-shared columns dropped: []\n",
      "Number of rows in df: 164\n",
      "Number of rows in newdf: 164\n",
      "305\n",
      "The DataFrames are equal.\n",
      "305\n",
      "305\n",
      "[]\n",
      "Original df columns: 305\n",
      "Updated df2 columns: 305\n",
      "Non-shared columns dropped: []\n",
      "Number of rows in df: 166\n",
      "Number of rows in newdf: 166\n",
      "305\n",
      "The DataFrames are equal.\n",
      "305\n",
      "305\n",
      "[]\n",
      "Original df columns: 305\n",
      "Updated df2 columns: 305\n",
      "Non-shared columns dropped: []\n",
      "Number of rows in df: 170\n",
      "Number of rows in newdf: 170\n",
      "305\n",
      "The DataFrames are equal.\n",
      "305\n",
      "305\n",
      "[]\n",
      "Original df columns: 305\n",
      "Updated df2 columns: 305\n",
      "Non-shared columns dropped: []\n",
      "Number of rows in df: 174\n",
      "Number of rows in newdf: 174\n",
      "305\n",
      "The DataFrames are equal.\n",
      "305\n",
      "305\n",
      "[]\n",
      "Original df columns: 305\n",
      "Updated df2 columns: 305\n",
      "Non-shared columns dropped: []\n",
      "Number of rows in df: 168\n",
      "Number of rows in newdf: 168\n",
      "305\n",
      "The DataFrames are equal.\n",
      "305\n",
      "305\n",
      "[]\n",
      "Original df columns: 305\n",
      "Updated df2 columns: 305\n",
      "Non-shared columns dropped: []\n",
      "Number of rows in df: 164\n",
      "Number of rows in newdf: 164\n",
      "305\n",
      "The DataFrames are equal.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "trail = 'ps'\n",
    "# Define year and file paths\n",
    "for year in range(2014,2025):\n",
    "\n",
    "\n",
    "    file = f'year_files/{year}{trail}_teamgames.csv'\n",
    "    file2 = f'year_files/{year}{trail}_teamgames_updated.csv'\n",
    "\n",
    "    # Load the data\n",
    "    df = pd.read_csv(file)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    update_copy=df2.copy()\n",
    "    print(len(df.columns))\n",
    "    print(len(df2.columns))\n",
    "    # Drop non-shared columns from df2\n",
    "    non_shared_columns = list(set(df2.columns) - set(df.columns))\n",
    "    print(non_shared_columns)\n",
    "    newdf = df2.drop(columns=non_shared_columns)\n",
    "\n",
    "    # Ensure column order matches df\n",
    "    newdf = newdf[df.columns]\n",
    "\n",
    "    # Print basic information\n",
    "    print(f\"Original df columns: {len(df.columns)}\")\n",
    "    print(f\"Updated df2 columns: {len(df2.columns)}\")\n",
    "    print(f\"Non-shared columns dropped: {non_shared_columns}\")\n",
    "    print(f\"Number of rows in df: {len(df)}\")\n",
    "    print(f\"Number of rows in newdf: {len(newdf)}\")\n",
    "\n",
    "    # Check if the DataFrames are equal\n",
    "    if df.equals(newdf):\n",
    "        print(len(update_copy.columns))\n",
    "        update_copy.to_csv(file,index=False)\n",
    "        print(\"The DataFrames are equal.\")\n",
    "        \n",
    "    else:\n",
    "        print(\"The DataFrames are NOT equal.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
